# üöÄ Algoritmo QuickSort Paralelo en C con MPI
## üìö Proyecto de Computaci√≥n Paralela: QuickSort
Este proyecto implementa una versi√≥n paralela del algoritmo de ordenamiento QuickSort en C, utilizando MPI para distribuir el trabajo en varios procesos. Se centra en la eficiencia de ordenamiento de grandes conjuntos de datos en un entorno de m√∫ltiples procesos, midiendo el rendimiento en t√©rminos de tiempo de ejecuci√≥n.

## üß© Algoritmo QuickSort Paralelo
#### Estrategia y Distribuci√≥n de Trabajo
1. El conjunto de datos se divide en fragmentos que son distribuidos entre los procesos disponibles.
2. Cada proceso aplica el algoritmo QuickSort secuencial a su fragmento. 
3. Finalmente, el proceso ra√≠z fusiona los fragmentos ordenados para obtener el conjunto de datos completo en orden ascendente.

## üîç Caracter√≠sticas T√©cnicas
- **Paralelizaci√≥n con MPI**: Dividir y fusionar fragmentos de manera eficiente.
- **Complejidad Temporal (Promedio)**: O(n log n) para el proceso completo.
- **Distribuci√≥n Din√°mica de Fragmentos**: Para balancear la carga entre procesos.

## üíª Distribuci√≥n y Recolecci√≥n de Datos con MPI
#### Distribuir Tama√±os de Fragmento: `MPI_Scatter`
```c
int localFragmentSize;
MPI_Scatter(fragmentSizes, 1, MPI_INT, &localFragmentSize, 1, MPI_INT, 0, MPI_COMM_WORLD);
```
**Prop√≥sito**: Distribuir el tama√±o de cada fragmento de datos a los procesos.
**Funcionamiento**: Env√≠a a cada proceso el tama√±o del fragmento que procesar√°, para reservar la memoria necesaria en cada proceso.

#### Enviar Fragmentos de Datos: `MPI_Scatterv`
```c
localFragment = (int *)malloc(localFragmentSize * sizeof(int));
MPI_Scatterv(fullArray, fragmentSizes, displacements, MPI_INT, localFragment, localFragmentSize, MPI_INT, 0, MPI_COMM_WORLD);
```
**Prop√≥sito**: Enviar el fragmento de datos correspondiente a cada proceso.
**Funcionamiento**: Distribuye fragmentos espec√≠ficos de `fullArray` a cada proceso basado en `fragmentSizes` y `displacements`.

#### Recolectar Fragmentos Ordenados: `MPI_Gatherv`
```c
MPI_Gatherv(localFragment, localFragmentSize, MPI_INT, fullArray, fragmentSizes, displacements, MPI_INT, 0, MPI_COMM_WORLD);
```
**Prop√≥sito**: Recoger los fragmentos ordenados de cada proceso en el proceso ra√≠z.
**Funcionamiento**: Usa `fragmentSizes` y `displacements` para colocar los fragmentos en sus posiciones correctas en `fullArray`.

## üõ†Ô∏è Compilaci√≥n y Ejecuci√≥n Paralela
### Compilaci√≥n
Compila el programa con el compilador MPI (`mpicc`):
```bash
mpicc -o quickParallel ParallelQuickSort.c
```
### Ejecuci√≥n
Ejecuta el programa en modo paralelo especificando la cantidad de procesos con `mpiexec`:
```bash
mpiexec -n (cantidad procesos) ./quickParallel
```
Por ejemplo, para ejecutar el programa con 10 procesos:
```bash
mpiexec -n 10 ./quickParallel
```

## üìä Rendimiento y Mediciones en Cl√∫ster
Se realizaron pruebas en un cl√∫ster con 10 nodos para evaluar el rendimiento de la versi√≥n paralela en comparaci√≥n con la versi√≥n secuencial.

| Cantidad de Datos | Tipo | Nodos | Tiempo de Ejecuci√≥n (s) |
| ----------------- | ---- | ------ | ----------------------- |
| 100 millones de n√∫meros | Paralelo | 10 | 68.239076138 |
| 100 millones de n√∫meros | Secuencial (sin MPI) | 1 | 253.353401354 |

**Conclusiones**:
- La versi√≥n paralela en cl√∫ster reduce significativamente el tiempo de ejecuci√≥n en comparaci√≥n con la versi√≥n secuencial, logrando una mejora de casi 4 veces en este caso.
- El uso de 10 nodos permite balancear la carga de trabajo y aprovechar la capacidad de procesamiento distribuido.

## üíª Funciones para Generaci√≥n, Distribuci√≥n y Fusi√≥n del Arreglo
#### `fullArray = (int *)malloc(MAX_NUMBERS * sizeof(int))`
**Prop√≥sito**: Crear un arreglo grande que contendr√° todos los elementos a ordenar.
**Funcionamiento**:
- El proceso ra√≠z genera un conjunto de datos aleatorios en este arreglo para simular una gran cantidad de datos (hasta `MAX_NUMBERS`).
- Los valores generados est√°n en el rango de 0 a 999999.

#### `fragmentSizes` y `displacements`
```c
fragmentSizes = (int *)malloc(numProcesses * sizeof(int));
displacements = (int *)malloc(numProcesses * sizeof(int));

int baseFragmentSize = numElements / numProcesses;
int remainingElements = numElements % numProcesses;

for (int i = 0; i < numProcesses; i++) {
    fragmentSizes[i] = baseFragmentSize + (i < remainingElements ? 1 : 0);
    displacements[i] = (i == 0) ? 0 : displacements[i - 1] + fragmentSizes[i - 1];
}
```
**Prop√≥sito**: Determinar los tama√±os de fragmento y las posiciones de inicio para cada proceso.
**Funcionamiento**:
- Calcula el tama√±o base de fragmento (`baseFragmentSize`) dividiendo el n√∫mero de elementos por la cantidad de procesos.
- Balanceo de carga: Los elementos restantes se asignan a los primeros procesos para garantizar un reparto equitativo.
- `fragmentSizes` almacena el tama√±o de fragmento para cada proceso.
- `displacements` guarda el √≠ndice de inicio de cada fragmento en `fullArray`.

#### Fusionar Fragmentos Ordenados: `mergeSortedFragments(int *array, int totalSize, int *fragmentSizes, int worldSize)`
```c
int *tempArray = (int *)malloc(totalSize * sizeof(int));
int currentIndices[worldSize];
int fragmentStartIndices[worldSize];

fragmentStartIndices[0] = 0;
for (int i = 0; i < worldSize; i++) {
    currentIndices[i] = fragmentStartIndices[i];
    if (i < worldSize - 1) {
        fragmentStartIndices[i + 1] = fragmentStartIndices[i] + fragmentSizes[i];
    }
}

for (int i = 0; i < totalSize; i++) {
    int minValue = __INT_MAX__;
    int minIndex = -1;
    for (int j = 0; j < worldSize; j++) {
        if (currentIndices[j] < fragmentStartIndices[j] + fragmentSizes[j] && array[currentIndices[j]] < minValue) {
            minValue = array[currentIndices[j]];
            minIndex = j;
        }
    }
    tempArray[i] = minValue;
    currentIndices[minIndex]++;
}

for (int i = 0; i < totalSize; i++) {
    array[i] = tempArray[i];
}
free(tempArray);
```
**Prop√≥sito**: Fusionar los fragmentos ordenados en un solo arreglo en el proceso ra√≠z.
**Funcionamiento**:
- Usa un arreglo temporal `tempArray` para mantener el resultado de la fusi√≥n.
- Mantiene √≠ndices en `currentIndices` que avanzan por cada fragmento, seleccionando el valor m√≠nimo entre los fragmentos actuales y coloc√°ndolo en `tempArray`.
- Finalmente, `tempArray` se copia a `array`, que contiene los datos fusionados y ordenados.

## üìä Medici√≥n de Rendimiento en Tiempo Real
El programa mide el tiempo de ejecuci√≥n total desde la distribuci√≥n hasta la fusi√≥n, 

- Segundos
- Milisegundos
- Nanosegundos
  
utilizando `MPI_Wtime()` para obtener una medici√≥n precisa del tiempo de ejecuci√≥n.

## üî¨ An√°lisis de Complejidad
- **Mejor Caso**: O(n log n) - Particiones equilibradas.
- **Peor Caso**: O(n¬≤) - Arreglo ya ordenado o inversamente ordenado.
- **Caso Promedio**: O(n log n) - Con datos aleatorios.

## üíª Tecnolog√≠as

<div align="center">
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/c/c-original.svg" height="40" alt="c logo" />
  <img src="https://www.open-mpi.org/images/open-mpi-logo.png" height="40" alt="Open MPI logo" />
</div>

## üßëüèª‚Äçüíª Autor:

Valentin Mathey | <a href="https://github.com/valentinmathey">@valentinmathey</a>

[![Discord](https://img.shields.io/badge/Discord-%237289DA.svg?logo=discord&logoColor=white)](https://discord.gg/valentinmathey) [![Facebook](https://img.shields.io/badge/Facebook-%231877F2.svg?logo=Facebook&logoColor=white)](https://facebook.com/ValentinEzequielMathey) [![Instagram](https://img.shields.io/badge/Instagram-%23E4405F.svg?logo=Instagram&logoColor=white)](https://instagram.com/valen.mathey/) [![LinkedIn](https://img.shields.io/badge/LinkedIn-%230077B5.svg?logo=linkedin&logoColor=white)](https://linkedin.com/in/valentin-mathey) [![X](https://img.shields.io/badge/X-%231DA1F2.svg?logo=X&logoColor=white)](https://twitter.com/valen_mathey)
